{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67fa6ab-1de3-4e05-abbc-ec5ee1f7b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\samgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597eac63-d224-4dab-9461-fe960639103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('7500covid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772451d8-cf77-43bb-8b7f-1100c9500537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\samgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\samgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\samgh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt_tab')\n",
    "# Initialize stop words, English words corpus, and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "english_words = set(words.words())\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Cleantext'] = df['original_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "833a9942-4419-4c5a-9f4e-87a42d1e2b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X_train: 6000\n",
      "X_test: 1500)\n",
      "Label mapping: {'negative': np.int64(0), 'neutral': np.int64(1), 'positive': np.int64(2)}\n",
      "Train metrics: {'accuracy': 0.73, 'precision': 0.7319217657377514, 'recall': 0.73, 'f1_score': 0.728249353070612}\n",
      "Test metrics: {'accuracy': 0.734, 'precision': 0.7364382178467752, 'recall': 0.734, 'f1_score': 0.7321871933276178}\n",
      "Full dataset metrics: {'accuracy': 0.7308, 'precision': 0.7327493396785993, 'recall': 0.7308, 'f1_score': 0.7290203014587685}\n",
      "                                                   text true_label vader_pred\n",
      "1152  yet voted tax scam billionaires corporations a...   negative   negative\n",
      "837   rt seven point action plan combat present cris...   negative   negative\n",
      "4932  rt â€™ despicable radical proabortion left amp p...    neutral   negative\n",
      "488   rt day stand india stand humanity feed many pe...   negative   negative\n",
      "6517  amidst covid chaos would like thank lord bless...   positive   positive\n",
      "3031                 rt teaming whored flagkeep reading    neutral   negative\n",
      "1478  rt covid undoubtedly impact match order inspir...   negative   positive\n",
      "4894       world return business usual covid say mayors    neutral    neutral\n",
      "3423  covid drivers forfeit vehicles govt violating ...    neutral   negative\n",
      "75    millions people living serious mental illness ...   negative   negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "label_mapping_Y = {'neg': 'negative', 'neu': 'neutral', 'pos': 'positive'}\n",
    "Y_std = df['sentiment'].replace(label_mapping_Y)\n",
    "X = df['Cleantext']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y_std, test_size=1500, random_state=42, stratify=Y_std\n",
    ")\n",
    "\n",
    "print(f'(X_train: {len(X_train)}\\nX_test: {len(X_test)})')\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y_std)  \n",
    "\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_to_class(text):\n",
    "    compound = analyzer.polarity_scores(text)['compound']\n",
    "    if compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "\n",
    "y_train_pred = X_train.apply(vader_to_class)\n",
    "y_test_pred = X_test.apply(vader_to_class)\n",
    "\n",
    "\n",
    "y_train_pred_num = label_encoder.transform(y_train_pred)\n",
    "y_test_pred_num = label_encoder.transform(y_test_pred)\n",
    "\n",
    "\n",
    "y_full_true = np.concatenate([y_train_encoded, y_test_encoded])\n",
    "y_full_pred_num = np.concatenate([y_train_pred_num, y_test_pred_num])\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "\n",
    "train_metrics = evaluate_metrics(y_train_encoded, y_train_pred_num)\n",
    "test_metrics = evaluate_metrics(y_test_encoded, y_test_pred_num)\n",
    "full_metrics = evaluate_metrics(y_full_true, y_full_pred_num)\n",
    "\n",
    "\n",
    "print(\"Train metrics:\", train_metrics)\n",
    "print(\"Test metrics:\", test_metrics)\n",
    "print(\"Full dataset metrics:\", full_metrics)\n",
    "\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'text': X_test.iloc[:10],\n",
    "    'true_label': y_test.iloc[:10],\n",
    "    'vader_pred': y_test_pred.iloc[:10]\n",
    "})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cb02200-a372-40b0-8230-dfa1a47f1431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.75      0.75      2000\n",
      "     neutral       0.74      0.63      0.68      2000\n",
      "    positive       0.70      0.81      0.75      2000\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.73      0.73      0.73      6000\n",
      "weighted avg       0.73      0.73      0.73      6000\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.76      0.75       500\n",
      "     neutral       0.76      0.63      0.69       500\n",
      "    positive       0.71      0.81      0.76       500\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.74      0.73      0.73      1500\n",
      "weighted avg       0.74      0.73      0.73      1500\n",
      "\n",
      "Full dataset classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75      2500\n",
      "     neutral       0.74      0.63      0.68      2500\n",
      "    positive       0.70      0.81      0.75      2500\n",
      "\n",
      "    accuracy                           0.73      7500\n",
      "   macro avg       0.73      0.73      0.73      7500\n",
      "weighted avg       0.73      0.73      0.73      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Class names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Train\n",
    "print(\"Train classification report:\")\n",
    "print(classification_report(y_train_encoded, y_train_pred_num, target_names=class_names, zero_division=0))\n",
    "\n",
    "# Test\n",
    "print(\"Test classification report:\")\n",
    "print(classification_report(y_test_encoded, y_test_pred_num, target_names=class_names, zero_division=0))\n",
    "\n",
    "# Full dataset\n",
    "print(\"Full dataset classification report:\")\n",
    "print(classification_report(y_full_true, y_full_pred_num, target_names=class_names, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79808ef-c3ae-4f13-a29e-11247f78484e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
